{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using DSX Local Machine Learning Service for Model Training and Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook shows how to use machine learning libraries and services from DSX Local to train, save, deploy and evaluate a model and make a prediction for new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Table of contents\n",
    "- [Prepare the environment](#prepare_environment)\n",
    "- [Load data](#load_data)\n",
    "- [Access and manipulate data](#access_manipulate_data)\n",
    "- [Save the model](#save_model)\n",
    "- [Evaluate the model](#evaluate_model)\n",
    "- [Make a prediction](#make_prediction)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"prepare_environment\"></a>\n",
    "## Prepare the environment\n",
    "\n",
    "Import machine learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar\n",
      "Finished download of spark-kernel-brunel-all-2.3.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar -magic https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "//import libraries\n",
    "import org.apache.spark.{SparkConf, SparkContext, SparkFiles}\n",
    "import org.apache.spark.sql.{SQLContext, SparkSession, Row}\n",
    "import org.apache.spark.SparkFiles\n",
    "\n",
    "import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, DecisionTreeClassifier}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "import org.apache.spark.ml.ibm.transformers.RenameColumn\n",
    "\n",
    "import com.ibm.analytics.ngp.dsxML._\n",
    "import com.ibm.analytics.ngp.ingest.Sampling\n",
    "import com.ibm.analytics.ngp.util._\n",
    "import com.ibm.analytics.ngp.pipeline.evaluate.{Evaluator,MLProblemType}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"load_data\"></a>\n",
    "## Load data \n",
    "The 1983 Data Exposition dataset was collected by Ernesto Ramos and David Donoho and dealt with automobiles. Data on mpg, cylinders, displacement, was provided for 406 different cars, each identified by name. The dataset is freely available on the Data Science Experience home page.\n",
    "\n",
    "\n",
    "Perform the following steps to upload this dataset:\n",
    "1. Go to the <a href=\"https://apsportal.ibm.com/exchange/public/entry/view/c81e9be8daf6941023b9dc86f303053b\" target=\"_blank\">Car performance data</a> card on the Data Science Experience home page.\n",
    "1. Click the download button.\n",
    "1. Click the **Create new** icon on the notebook action bar, and use **Add data set** button to add the downloaded cars.csv file as a `Local File`. \n",
    "\n",
    "The data file is listed on the **Local Data** pane in the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"access_manipulate_data\"></a>\n",
    "## Access and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To add the code to access the data file, click the next code cell and select **Insert Spark DataFrame in Scala** in the **Insert To Code** drop-down list below the data file in the `Local Data` pane in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+----------+------+------------+----+--------+--------------------+\n",
      "|mpg|cylinders|engine|horsepower|weight|acceleration|year|  origin|                name|\n",
      "+---+---------+------+----------+------+------------+----+--------+--------------------+\n",
      "| 18|        8| 307.0|       130|  3504|        12.0|  70|American|chevrolet chevell...|\n",
      "| 15|        8| 350.0|       165|  3693|        11.5|  70|American|   buick skylark 320|\n",
      "| 18|        8| 318.0|       150|  3436|        11.0|  70|American|  plymouth satellite|\n",
      "| 16|        8| 304.0|       150|  3433|        12.0|  70|American|       amc rebel sst|\n",
      "| 17|        8| 302.0|       140|  3449|        10.5|  70|American|         ford torino|\n",
      "+---+---------+------+----------+------+------------+----+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Note: Make sure the df variable in the following cell is the same as the generated code from insertToCode.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Due to missing data in `mpg` and `horsepower` columns, they will be excluded from the dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------------+----+--------+--------------------+\n",
      "|cylinders|engine|weight|acceleration|year|  origin|                name|\n",
      "+---------+------+------+------------+----+--------+--------------------+\n",
      "|        8| 307.0|  3504|        12.0|  70|American|chevrolet chevell...|\n",
      "|        8| 350.0|  3693|        11.5|  70|American|   buick skylark 320|\n",
      "|        8| 318.0|  3436|        11.0|  70|American|  plymouth satellite|\n",
      "|        8| 304.0|  3433|        12.0|  70|American|       amc rebel sst|\n",
      "|        8| 302.0|  3449|        10.5|  70|American|         ford torino|\n",
      "+---------+------+------+------------+----+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val carsDataRaw = df0\n",
    "val carsModData = carsDataRaw.drop(\"mpg\", \"horsepower\")\n",
    "carsModData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the model training process, the original dataset will be split into training dataset and testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training dataset: 348\n",
      "Number of testing dataset: 58\n"
     ]
    }
   ],
   "source": [
    "val splitted_data = carsModData.randomSplit(Array(0.85, 0.15), 24)\n",
    "val train_data = splitted_data(0)\n",
    "val test_data = splitted_data(1)\n",
    "\n",
    "println(\"Number of training dataset: \" + train_data.count())\n",
    "println(\"Number of testing dataset: \" + test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following task is to set the input columns for model training, and use the corresponding algorithms to train the model. In this example, Linear Regression method is used to evaluate `weight` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val originIndexer = new StringIndexer().setInputCol(\"origin\").setOutputCol(\"origin_code\")\n",
    "\n",
    "val vectorAssembler_features = new VectorAssembler().setInputCols(Array(\"cylinders\",\n",
    "                                                                 \"engine\",\n",
    "                                                                 \"acceleration\",\n",
    "                                                                 \"year\",\n",
    "                                                                 \"origin_code\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val rf = new LinearRegression().setLabelCol(\"weight\").setFeaturesCol(\"features\")\n",
    "val pipeline = new Pipeline().setStages(Array(originIndexer,vectorAssembler_features,rf))\n",
    "val model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"save_model\"></a>\n",
    "## Save the model\n",
    "After the model is successfully trained, save the model. The model name can be customized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user-home/999/DSX_Projects/dsx-samples/models/CarsModelScala/1"
     ]
    }
   ],
   "source": [
    "val ml_client = ML()\n",
    "val modelName = \"CarsModelScala\"\n",
    "val fileName = \"Train+and+predict+with+Scala+machine+learning.ipynb\"\n",
    "val saveResult = ml_client.save(model, train_data, test_data, None, modelName, \"\", \n",
    "                                fileName, \n",
    "                                \"Regression\", \n",
    "                                com.ibm.analytics.ngp.dsxML.MetaNames.LABEL_FIELD -> \"weight\")\n",
    "print(saveResult.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"evaluate_model\"></a>\n",
    "## Evaluate the model\n",
    "The model performance can be evaluated using the R Square for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Square of Test Data: 0.8639768443077398\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.{LinearRegressionSummary, LinearRegressionModel}\n",
    "\n",
    "val testData = model.transform(test_data).drop(\"prediction\")\n",
    "val metric = model.stages(2).asInstanceOf[LinearRegressionModel].evaluate(testData).asInstanceOf[LinearRegressionSummary]\n",
    "println(s\"R Square of Test Data: ${metric.r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"make_prediction\"></a>\n",
    "## Make a prediction\n",
    "\n",
    "After deployment, the endpoint of model can be used to give prediction for new data using the online scoring service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dsxl-api.ibm-private-cloud.svc.cluster.local/v3/project/score/Scala/spark-2.0/dsx-samples/CarsModelScala/1"
     ]
    }
   ],
   "source": [
    "import play.api.libs.json._\n",
    "import scalaj.http.{Http, HttpOptions}\n",
    "\n",
    "val projectName = sys.env(\"DSX_PROJECT_NAME\")\n",
    "\n",
    "val scoringURL = s\"https://dsxl-api.ibm-private-cloud.svc.cluster.local/v3/project/score/Scala/spark-2.0/${projectName}/${modelName}/1\"\n",
    "\n",
    "print(scoringURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "New data is provided in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"acceleration\":11.1,\"cylinders\":6,\"year\":79,\"origin\":\"American\",\"engine\":289}]"
     ]
    }
   ],
   "source": [
    "val json_map = Json.toJson(List(Json.toJson(Map(\"cylinders\" -> Json.toJson(6), \n",
    "                                                \"engine\" -> Json.toJson(289), \n",
    "                                                \"acceleration\" -> Json.toJson(11.1), \n",
    "                                                \"year\" -> Json.toJson(79), \n",
    "                                                \"origin\" -> Json.toJson(\"American\")))))\n",
    "val payload_scoring = Json.stringify(json_map)\n",
    "\n",
    "print (payload_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The model evaluates new data and give an estimate scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HttpResponse({\"success\":true,\"description\":\"Success\",\"object\":{\"error\":\"\",\"output\":{\"classes\":[],\"predictions\":[3553],\"probabilities\":[]},\"returnCode\":\"0\"}},200,Map(Connection -> Vector(keep-alive), Content-Encoding -> Vector(gzip), Content-Type -> Vector(application/json), Date -> Vector(Tue, 16 Jan 2018 06:16:43 GMT), Server -> Vector(openresty), Status -> Vector(HTTP/1.1 200 OK), Transfer-Encoding -> Vector(chunked), Vary -> Vector(Accept-Encoding), X-Powered-By -> Vector(Express)))"
     ]
    }
   ],
   "source": [
    "val authToken = sys.env(\"DSX_TOKEN\")\n",
    "val response_scoring = Http(scoringURL).postData(payload_scoring).header(\"Content-Type\", \"application/json\").header(\"Authorization\", authToken).option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).option(HttpOptions.allowUnsafeSSL).asString\n",
    "\n",
    "print (response_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "In this sample, you learned how to use DSX Local machine learning services and libraries. You also learned how to split data for model training, how to customize, save and deploy the model, and how to use model endpoint for new data evaluation and scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Note: To save resources and get the best performance please use the code below to stop the kernel before exiting your notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2017. Released as licensed Sample Materials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
